{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\n\n# Configure GPU memory usage\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:\n        # Currently, memory growth needs to be the same across GPUs\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n    except RuntimeError as e:\n        # Memory growth must be set before GPUs have been initialized\n        print(e)\n\n# Session configuration\nconfig = tf.compat.v1.ConfigProto()\nconfig.gpu_options.allow_growth = True\nconfig.log_device_placement = True\nsess = tf.compat.v1.Session(config=config)\ntf.compat.v1.keras.backend.set_session(sess)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport random\nimport tensorflow as tf\nfrom keras import layers, models\nfrom keras.callbacks import EarlyStopping\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import load_model\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, roc_auc_score\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pic=plt.imread(\"/kaggle/input/state-farm-distracted-driver-detection/imgs/train/c8/img_100814.jpg\")\nplt.imshow(pic, cmap=\"gray\")\nprint(pic.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DataDirectory = '/kaggle/input/state-farm-distracted-driver-detection/imgs/train'\nTestDirectory= '/kaggle/input/state-farm-distracted-driver-detection/imgs/test'\nClasses = ['c0','c1','c2','c3','c4','c5','c6','c7','c8','c9']\nimg_size = 240","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_training_data(Classes, Datadirectory, img_size, max_images_per_class=1500):\n    training_data = []\n    for category in Classes:\n        path = os.path.join(Datadirectory, category)\n        class_num = Classes.index(category)\n        image_count = 0  # Initialize a counter for images in the class\n\n        for img in os.listdir(path):\n            if image_count >= max_images_per_class:\n                break  # Stop processing after reaching the maximum number of images per class\n            \n            img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n            \n            # Resize the image while maintaining the aspect ratio\n            desired_size = (img_size, img_size)\n            height, width = img_array.shape\n            aspect_ratio = width / height\n\n            if aspect_ratio >= 1:\n                new_width = desired_size[0]\n                new_height = int(new_width / aspect_ratio)\n            else:\n                new_height = desired_size[1]\n                new_width = int(new_height * aspect_ratio)\n\n            resized_image = cv2.resize(img_array, (new_width, new_height))\n\n            # Pad the resized image to make it square (img_size x img_size)\n            pad_width = (desired_size[1] - new_height) // 2\n            pad_height = (desired_size[0] - new_width) // 2\n            padded_image = np.pad(resized_image, ((pad_width, pad_width), (pad_height, pad_height)), mode='constant', constant_values=0)\n\n            # Convert the grayscale image to RGB\n            rgb_image = cv2.cvtColor(padded_image, cv2.COLOR_GRAY2RGB)\n            \n            training_data.append([rgb_image, class_num])\n            image_count += 1  # Increment the counter for images in the class\n\n    print(\"Data processing completed.\")\n    return training_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\n\ndef create_testing_data(TestDirectory, img_size, max_images=8000):\n    testing_data = []\n    path = os.path.join(TestDirectory, '')\n    count = 0  # Initialize a counter\n\n    for img in os.listdir(path):\n        if count >= max_images:\n            break  # Stop processing after reaching the maximum number of images\n        \n        img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n        \n        # Resize the image while maintaining the aspect ratio\n        desired_size = (img_size, img_size)\n        height, width = img_array.shape\n        aspect_ratio = width / height\n\n        if aspect_ratio >= 1:\n            new_width = desired_size[0]\n            new_height = int(new_width / aspect_ratio)\n        else:\n            new_height = desired_size[1]\n            new_width = int(new_height * aspect_ratio)\n\n        resized_image = cv2.resize(img_array, (new_width, new_height))\n\n        # Pad the resized image to make it square (img_size x img_size)\n        pad_width = (desired_size[1] - new_height) // 2\n        pad_height = (desired_size[0] - new_width) // 2\n        padded_image = np.pad(resized_image, ((pad_width, pad_width), (pad_height, pad_height)), mode='constant', constant_values=0)\n\n        # Convert the grayscale image to RGB\n        rgb_image = cv2.cvtColor(padded_image, cv2.COLOR_GRAY2RGB)\n\n        testing_data.append([rgb_image])\n        count += 1  # Increment the counter\n\n    print(\"Data processing completed.\")\n    return testing_data\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_data= create_training_data(Classes, DataDirectory, img_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testing_data= create_testing_data(TestDirectory, img_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(training_data))\nprint(len(testing_data))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = []\ny = []\nfor features, label in training_data:\n    X.append(features)\n    y.append(label)\n\nX = np.array(X).reshape(-1, img_size, img_size, 3)\nY=np.array(y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Builidng the model","metadata":{}},{"cell_type":"code","source":"# Define the input shape\ninput_shape = (240, 240, 3)\nmodel = models.Sequential()\n\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(256, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(384, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(512, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(1024, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\n# Flatten the output from Conv2D layers\nmodel.add(layers.Flatten())\n\n# Add fully connected layers with specified parameters\nmodel.add(layers.Dense(16384, activation='relu'))\nmodel.add(layers.Dense(180, activation='relu'))\nmodel.add(layers.Dense(32, activation='relu'))\nmodel.add(layers.Dense(10,activation='softmax'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss=\"binary_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n\nearly_stopping_callback = EarlyStopping(monitor='val_accuracy', patience=4, mode='max', verbose=1)\n\nX_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42, shuffle=True)\n\nY_train = np_utils.to_categorical(y_train,num_classes=10)\nY_val = np_utils.to_categorical(y_test,num_classes=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(X_train, Y_train, epochs=20, batch_size=32, validation_data=(X_val, Y_val), callbacks=[early_stopping_callback])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}