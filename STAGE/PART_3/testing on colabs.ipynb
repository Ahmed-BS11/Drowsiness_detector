{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54iOEVKofljc",
        "outputId": "e256d72c-fa0c-485a-c193-b2b2e991d2c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "old_name = r\"/root/Untitled Folder\"\n",
        "new_name = r\"/root/.kaggle\"\n",
        "os.rename(old_name, new_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "ifpt6WlNiIrH",
        "outputId": "6afe5369-963a-4809-eb16-9a40f3501210"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-93dfbe30708f>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mold_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr\"/root/Untitled Folder\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnew_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr\"/root/.kaggle\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m: [Errno 39] Directory not empty: '/root/Untitled Folder' -> '/root/.kaggle'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c state-farm-distracted-driver-detection\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z16AoJOwfnNp",
        "outputId": "2c04f72e-821b-47b9-d7d2-4d669f15ad72"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "state-farm-distracted-driver-detection.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip state-farm-distracted-driver-detection.zip"
      ],
      "metadata": {
        "id": "RhqK2wFxfy3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from keras import layers, models\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import load_model\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, roc_auc_score\n",
        "\n"
      ],
      "metadata": {
        "id": "xUXmYUnvi5pt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pic=plt.imread(\"/content/imgs/train/c0/img_100026.jpg\")\n",
        "plt.imshow(pic, cmap=\"gray\")\n",
        "print(pic.shape)"
      ],
      "metadata": {
        "id": "R8HeuK0pjT4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DataDirectory = '/content/imgs/train'\n",
        "TestDirectory= '/content/imgs/test'\n",
        "Classes = ['c0','c1','c2','c3','c4','c5','c6','c7','c8','c9']\n",
        "img_size = 120"
      ],
      "metadata": {
        "id": "siKJh9RZjT04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import concurrent.futures\n",
        "\n",
        "def preprocess_image(image_path, img_size):\n",
        "    img_array = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    desired_size = (img_size, img_size)\n",
        "    height, width = img_array.shape\n",
        "    aspect_ratio = width / height\n",
        "\n",
        "    if aspect_ratio >= 1:\n",
        "        new_width = desired_size[0]\n",
        "        new_height = int(new_width / aspect_ratio)\n",
        "    else:\n",
        "        new_height = desired_size[1]\n",
        "        new_width = int(new_height * aspect_ratio)\n",
        "\n",
        "    resized_image = cv2.resize(img_array, (new_width, new_height))\n",
        "\n",
        "    pad_width = (desired_size[1] - new_height) // 2\n",
        "    pad_height = (desired_size[0] - new_width) // 2\n",
        "    padded_image = np.pad(resized_image, ((pad_width, pad_width), (pad_height, pad_height)), mode='constant', constant_values=0)\n",
        "\n",
        "    rgb_image = cv2.cvtColor(padded_image, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "    # Normalize pixel values to [0, 1]\n",
        "    normalized_image = rgb_image / 255.0\n",
        "\n",
        "    return normalized_image\n",
        "\n",
        "def create_training_data(Classes, Datadirectory, img_size, max_images_per_class=1900):\n",
        "    training_data = []\n",
        "\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        futures = []\n",
        "\n",
        "        for class_num, category in enumerate(Classes):\n",
        "            path = os.path.join(Datadirectory, category)\n",
        "            image_count = 0\n",
        "\n",
        "            for img in os.listdir(path):\n",
        "                if image_count >= max_images_per_class:\n",
        "                    break\n",
        "\n",
        "                img_path = os.path.join(path, img)\n",
        "                futures.append(executor.submit(preprocess_image, img_path, img_size))\n",
        "\n",
        "                normalized_image = futures[-1].result()\n",
        "\n",
        "                training_data.append([normalized_image, class_num])\n",
        "                image_count += 1\n",
        "\n",
        "    print(\"Data processing completed.\")\n",
        "    return training_data\n"
      ],
      "metadata": {
        "id": "fdkk5MDQjTyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import concurrent.futures\n",
        "\n",
        "def preprocess_image(image_path, img_size):\n",
        "    img_array = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    desired_size = (img_size, img_size)\n",
        "    height, width = img_array.shape\n",
        "    aspect_ratio = width / height\n",
        "\n",
        "    if aspect_ratio >= 1:\n",
        "        new_width = desired_size[0]\n",
        "        new_height = int(new_width / aspect_ratio)\n",
        "    else:\n",
        "        new_height = desired_size[1]\n",
        "        new_width = int(new_height * aspect_ratio)\n",
        "\n",
        "    resized_image = cv2.resize(img_array, (new_width, new_height))\n",
        "\n",
        "    pad_width = (desired_size[1] - new_height) // 2\n",
        "    pad_height = (desired_size[0] - new_width) // 2\n",
        "    padded_image = np.pad(resized_image, ((pad_width, pad_width), (pad_height, pad_height)), mode='constant', constant_values=0)\n",
        "\n",
        "    rgb_image = cv2.cvtColor(padded_image, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "    # Normalize pixel values to [0, 1]\n",
        "    normalized_image = rgb_image / 255.0\n",
        "\n",
        "    return normalized_image\n",
        "\n",
        "def create_testing_data(TestDirectory, img_size, max_images=80_000_000):\n",
        "    testing_data = []\n",
        "    path = os.path.join(TestDirectory, '')\n",
        "    count = 0\n",
        "\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        futures = []\n",
        "\n",
        "        for img in os.listdir(path):\n",
        "            if count >= max_images:\n",
        "                break\n",
        "\n",
        "            img_path = os.path.join(path, img)\n",
        "            futures.append(executor.submit(preprocess_image, img_path, img_size))\n",
        "            count += 1\n",
        "\n",
        "        for future in concurrent.futures.as_completed(futures):\n",
        "            testing_data.append([future.result()])\n",
        "\n",
        "    print(\"Data processing completed.\")\n",
        "    return testing_data\n"
      ],
      "metadata": {
        "id": "6QEraM-XjTwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data= create_training_data(Classes, DataDirectory, img_size)"
      ],
      "metadata": {
        "id": "fj3K947FjTt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing_data= create_testing_data(TestDirectory, img_size)"
      ],
      "metadata": {
        "id": "1qMvu4VXjTrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.shuffle(training_data)"
      ],
      "metadata": {
        "id": "5Lwmn_hEjTpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(training_data))\n",
        "print(len(testing_data))"
      ],
      "metadata": {
        "id": "bu06NT8Gje8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y = []\n",
        "for features, label in training_data:\n",
        "    X.append(features)\n",
        "    y.append(label)\n",
        "\n",
        "X = np.array(X).reshape(-1, img_size, img_size, 3)\n",
        "Y=np.array(y)\n"
      ],
      "metadata": {
        "id": "O1rcwYQLje5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input shape\n",
        "input_shape = (120, 120, 3)\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(16, (3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.BatchNormalization())  # Add batch normalization\n",
        "model.add(layers.Dropout(0.5))  # Add dropout for regularization\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n"
      ],
      "metadata": {
        "id": "Lm5_waeOje3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "mDEwt97tje1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
        "\n",
        "early_stopping_callback = EarlyStopping(monitor='val_accuracy', patience=4, mode='max', verbose=1)\n",
        "\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42, shuffle=True)\n",
        "\n",
        "Y_train = to_categorical(Y_train,num_classes=10)\n",
        "Y_val = to_categorical(Y_val,num_classes=10)"
      ],
      "metadata": {
        "id": "cyenJ_0njeym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, Y_train, epochs=20, batch_size=32, validation_data=(X_val, Y_val), callbacks=[early_stopping_callback])\n"
      ],
      "metadata": {
        "id": "lQ6AiENijewe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y6tB2eKvjeuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = []\n",
        "X_test=testing_data\n",
        "print(len(X_test))\n",
        "#Y_test=np.array(y_test)"
      ],
      "metadata": {
        "id": "EWWqXS9FjrdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "num_parts = 10\n",
        "part_size = len(X_test) // num_parts\n",
        "X_test = np.array(X_test)  # Convert to NumPy array\n",
        "X_test = X_test.astype('float32') / 255.0\n",
        "# Process predictions in smaller batches\n",
        "batch_size = 32  # Adjust this based on your available memory\n",
        "\n",
        "all_predictions = []\n",
        "\n",
        "for i in range(num_parts):\n",
        "    start_idx = i * part_size\n",
        "    end_idx = (i + 1) * part_size\n",
        "    part_X_test = X_test[start_idx:end_idx]\n",
        "\n",
        "    num_batches = len(part_X_test) // batch_size\n",
        "    part_predictions = []\n",
        "\n",
        "    for j in range(num_batches):\n",
        "        batch_start = j * batch_size\n",
        "        batch_end = (j + 1) * batch_size\n",
        "        batch_predictions = model.predict(part_X_test[batch_start:batch_end])\n",
        "        part_predictions.append(batch_predictions)\n",
        "\n",
        "    # Process the remaining samples (not forming a complete batch)\n",
        "    remaining_samples = len(part_X_test) % batch_size\n",
        "    if remaining_samples > 0:\n",
        "        batch_start = num_batches * batch_size\n",
        "        batch_end = batch_start + remaining_samples\n",
        "        batch_predictions = model.predict(part_X_test[batch_start:batch_end])\n",
        "        part_predictions.append(batch_predictions)\n",
        "\n",
        "    all_predictions.append(np.concatenate(part_predictions, axis=0))\n",
        "\n",
        "# Concatenate all the predictions into a single array\n",
        "final_predictions = np.concatenate(all_predictions, axis=0)\n"
      ],
      "metadata": {
        "id": "1A97apy3jraA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame from the concatenated predictions\n",
        "Pred = pd.DataFrame(all_predictions, columns=['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])\n",
        "Pred.head()"
      ],
      "metadata": {
        "id": "VURiIIbrjrXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sub = pd.read_csv(\"/content/sample_submission.csv\")\n",
        "sample_sub.head()"
      ],
      "metadata": {
        "id": "KuCkC4emjrU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = pd.read_csv(\"/content/driver_imgs_list.csv\")\n",
        "img=img['img']\n",
        "img.head(20)"
      ],
      "metadata": {
        "id": "I5I_z5_hjrSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pred = pd.DataFrame(predictions, columns = ['c0','c1','c2','c3','c4','c5','c6','c7','c8','c9'])\n",
        "#Pred.head()"
      ],
      "metadata": {
        "id": "7t-ei0u_j18A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub = pd.concat((img, Pred), axis = 1)\n",
        "sub.head()"
      ],
      "metadata": {
        "id": "5hv65MXTj14j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub[['img', 'c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']].to_csv(r'/content/sub0.csv', index=False)"
      ],
      "metadata": {
        "id": "sivdQemej12g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UadzK-AmjrQU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}